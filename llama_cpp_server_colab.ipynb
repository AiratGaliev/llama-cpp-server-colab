{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AiratGaliev/llama-cpp-server-colab/blob/main/llama_cpp_server_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DC4zIEuXlTqg",
    "outputId": "bea6ab6d-53cc-4306-d0df-6f685766a785",
    "ExecuteTime": {
     "end_time": "2024-02-04T08:32:29.728227495Z",
     "start_time": "2024-02-04T08:31:27.579347757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/content'\n",
      "/home/airat/PycharmProjects/llama-cpp-server-colab\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\r\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\r\n",
      "/bin/bash: line 1: npm: command not found\r\n",
      "Using pip 23.2.1 from /home/airat/anaconda3/lib/python3.11/site-packages/pip (python 3.11)\r\n",
      "Collecting llama-cpp-python[server]==0.2.38\r\n",
      "  Downloading llama_cpp_python-0.2.38.tar.gz (10.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.7/10.7 MB\u001B[0m \u001B[31m2.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0mm\r\n",
      "\u001B[?25h  Running command pip subprocess to install build dependencies\r\n",
      "  Collecting scikit-build-core[pyproject]>=0.5.1\r\n",
      "    Obtaining dependency information for scikit-build-core[pyproject]>=0.5.1 from https://files.pythonhosted.org/packages/0c/5b/73dc7944ef0fdbe97626b40525f1f9ca2547d7c5229b358d45357ff62209/scikit_build_core-0.8.0-py3-none-any.whl.metadata\r\n",
      "    Using cached scikit_build_core-0.8.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "  Collecting packaging>=20.9 (from scikit-build-core[pyproject]>=0.5.1)\r\n",
      "    Obtaining dependency information for packaging>=20.9 from https://files.pythonhosted.org/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl.metadata\r\n",
      "    Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "  Collecting pathspec>=0.10.1 (from scikit-build-core[pyproject]>=0.5.1)\r\n",
      "    Obtaining dependency information for pathspec>=0.10.1 from https://files.pythonhosted.org/packages/cc/20/ff623b09d963f88bfde16306a54e12ee5ea43e9b597108672ff3a408aad6/pathspec-0.12.1-py3-none-any.whl.metadata\r\n",
      "    Using cached pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\r\n",
      "  Collecting pyproject-metadata>=0.5 (from scikit-build-core[pyproject]>=0.5.1)\r\n",
      "    Using cached pyproject_metadata-0.7.1-py3-none-any.whl (7.4 kB)\r\n",
      "  Using cached packaging-23.2-py3-none-any.whl (53 kB)\r\n",
      "  Using cached pathspec-0.12.1-py3-none-any.whl (31 kB)\r\n",
      "  Using cached scikit_build_core-0.8.0-py3-none-any.whl (139 kB)\r\n",
      "  Installing collected packages: pathspec, packaging, scikit-build-core, pyproject-metadata\r\n",
      "  \u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "  tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\r\n",
      "  tables 3.8.0 requires cython>=0.29.21, which is not installed.\r\n",
      "  spyder 5.4.3 requires pyqt5<5.16, which is not installed.\r\n",
      "  spyder 5.4.3 requires pyqtwebengine<5.16, which is not installed.\r\n",
      "  python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "  \u001B[0mSuccessfully installed packaging-23.2 pathspec-0.12.1 pyproject-metadata-0.7.1 scikit-build-core-0.8.0\r\n",
      "  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\r\n",
      "  Running command Getting requirements to build wheel\r\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hdone\r\n",
      "  Running command pip subprocess to install backend dependencies\r\n",
      "  Collecting ninja>=1.5\r\n",
      "    Obtaining dependency information for ninja>=1.5 from https://files.pythonhosted.org/packages/6d/92/8d7aebd4430ab5ff65df2bfee6d5745f95c004284db2d8ca76dcbfd9de47/ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata\r\n",
      "    Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\r\n",
      "  Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\r\n",
      "  Installing collected packages: ninja\r\n",
      "  Successfully installed ninja-1.11.1.1\r\n",
      "  Installing backend dependencies ... \u001B[?25l\u001B[?25hdone\r\n",
      "  Running command Preparing metadata (pyproject.toml)\r\n",
      "  \u001B[92m***\u001B[0m \u001B[1m\u001B[92mscikit-build-core 0.8.0\u001B[0m using \u001B[94mCMake 3.25.1\u001B[0m \u001B[91m(metadata_wheel)\u001B[0m\u001B[0m\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\r\n",
      "Collecting typing-extensions>=4.5.0 (from llama-cpp-python[server]==0.2.38)\r\n",
      "  Obtaining dependency information for typing-extensions>=4.5.0 from https://files.pythonhosted.org/packages/b7/f4/6a90020cd2d93349b442bfcb657d0dc91eee65491600b2cb1d388bc98e6b/typing_extensions-4.9.0-py3-none-any.whl.metadata\r\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "  Link requires a different Python (3.11.5 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/3a/be/650f9c091ef71cb01d735775d554e068752d3ff63d7943b26316dc401749/numpy-1.21.2.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\r\n",
      "  Link requires a different Python (3.11.5 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/5f/d6/ad58ded26556eaeaa8c971e08b6466f17c4ac4d786cd3d800e26ce59cc01/numpy-1.21.3.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\r\n",
      "  Link requires a different Python (3.11.5 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/fb/48/b0708ebd7718a8933f0d3937513ef8ef2f4f04529f1f66ca86d873043921/numpy-1.21.4.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\r\n",
      "  Link requires a different Python (3.11.5 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/c2/a8/a924a09492bdfee8c2ec3094d0a13f2799800b4fdc9c890738aeeb12c72e/numpy-1.21.5.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\r\n",
      "  Link requires a different Python (3.11.5 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/45/b7/de7b8e67f2232c26af57c205aaad29fe17754f793404f59c8a730c7a191a/numpy-1.21.6.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\r\n",
      "Collecting numpy>=1.20.0 (from llama-cpp-python[server]==0.2.38)\r\n",
      "  Obtaining dependency information for numpy>=1.20.0 from https://files.pythonhosted.org/packages/5a/62/007b63f916aca1d27f5fede933fda3315d931ff9b2c28b9c2cf388cd8edb/numpy-1.26.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading numpy-1.26.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.2/61.2 kB\u001B[0m \u001B[31m3.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting diskcache>=5.6.1 (from llama-cpp-python[server]==0.2.38)\r\n",
      "  Obtaining dependency information for diskcache>=5.6.1 from https://files.pythonhosted.org/packages/3f/27/4570e78fc0bf5ea0ca45eb1de3818a23787af9b390c0b0a0033a1b8236f9/diskcache-5.6.3-py3-none-any.whl.metadata\r\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\r\n",
      "Collecting jinja2>=2.11.3 (from llama-cpp-python[server]==0.2.38)\r\n",
      "  Obtaining dependency information for jinja2>=2.11.3 from https://files.pythonhosted.org/packages/30/6d/6de6be2d02603ab56e72997708809e8a5b0fbfee080735109b40a3564843/Jinja2-3.1.3-py3-none-any.whl.metadata\r\n",
      "  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\r\n",
      "Collecting uvicorn>=0.22.0 (from llama-cpp-python[server]==0.2.38)\r\n",
      "  Obtaining dependency information for uvicorn>=0.22.0 from https://files.pythonhosted.org/packages/c7/f3/29caa83f5795b20ed3aca357c648f3ae995ff6ff08e38b22387017abbdc5/uvicorn-0.27.0.post1-py3-none-any.whl.metadata\r\n",
      "  Downloading uvicorn-0.27.0.post1-py3-none-any.whl.metadata (6.4 kB)\r\n",
      "Collecting fastapi>=0.100.0 (from llama-cpp-python[server]==0.2.38)\r\n",
      "  Obtaining dependency information for fastapi>=0.100.0 from https://files.pythonhosted.org/packages/e3/cb/fa5122eec49e6bca91d3a332a3bc1dff3c12d093228e9e524cad3a7f1039/fastapi-0.109.1-py3-none-any.whl.metadata\r\n",
      "  Downloading fastapi-0.109.1-py3-none-any.whl.metadata (25 kB)\r\n",
      "Collecting pydantic-settings>=2.0.1 (from llama-cpp-python[server]==0.2.38)\r\n",
      "  Obtaining dependency information for pydantic-settings>=2.0.1 from https://files.pythonhosted.org/packages/5d/c9/8042368e9a1e6e229b5ec5d88449441a3ee8f8afe09988faeb190af30248/pydantic_settings-2.1.0-py3-none-any.whl.metadata\r\n",
      "  Downloading pydantic_settings-2.1.0-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Collecting sse-starlette>=1.6.1 (from llama-cpp-python[server]==0.2.38)\r\n",
      "  Obtaining dependency information for sse-starlette>=1.6.1 from https://files.pythonhosted.org/packages/50/04/b1569f95ce91fbfe35e5e6b3b11e8373ffe4fa81e998818c8c995a873896/sse_starlette-2.0.0-py3-none-any.whl.metadata\r\n",
      "  Downloading sse_starlette-2.0.0-py3-none-any.whl.metadata (5.4 kB)\r\n",
      "Collecting starlette-context<0.4,>=0.3.6 (from llama-cpp-python[server]==0.2.38)\r\n",
      "  Downloading starlette_context-0.3.6-py3-none-any.whl (12 kB)\r\n",
      "Collecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi>=0.100.0->llama-cpp-python[server]==0.2.38)\r\n",
      "  Obtaining dependency information for pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 from https://files.pythonhosted.org/packages/e4/37/3ffe6e7daa1ea1b4bf5228807a92ccbae538cf57c0c50b93564c310c11a8/pydantic-2.6.0-py3-none-any.whl.metadata\r\n",
      "  Downloading pydantic-2.6.0-py3-none-any.whl.metadata (81 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m81.8/81.8 kB\u001B[0m \u001B[31m3.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting starlette<0.36.0,>=0.35.0 (from fastapi>=0.100.0->llama-cpp-python[server]==0.2.38)\r\n",
      "  Obtaining dependency information for starlette<0.36.0,>=0.35.0 from https://files.pythonhosted.org/packages/03/13/c60c738da2fb69d60ee1dc5631e8d152352003cc0bc4ce39582bdd90e293/starlette-0.35.1-py3-none-any.whl.metadata\r\n",
      "  Downloading starlette-0.35.1-py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Collecting MarkupSafe>=2.0 (from jinja2>=2.11.3->llama-cpp-python[server]==0.2.38)\r\n",
      "  Obtaining dependency information for MarkupSafe>=2.0 from https://files.pythonhosted.org/packages/97/18/c30da5e7a0e7f4603abfc6780574131221d9148f323752c2755d48abad30/MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\r\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.0.1->llama-cpp-python[server]==0.2.38)\r\n",
      "  Obtaining dependency information for python-dotenv>=0.21.0 from https://files.pythonhosted.org/packages/6a/3e/b68c118422ec867fa7ab88444e1274aa40681c606d59ac27de5a5588f082/python_dotenv-1.0.1-py3-none-any.whl.metadata\r\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\r\n",
      "Collecting anyio (from sse-starlette>=1.6.1->llama-cpp-python[server]==0.2.38)\r\n",
      "  Obtaining dependency information for anyio from https://files.pythonhosted.org/packages/bf/cd/d6d9bb1dadf73e7af02d18225cbd2c93f8552e13130484f1c8dcfece292b/anyio-4.2.0-py3-none-any.whl.metadata\r\n",
      "  Downloading anyio-4.2.0-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Collecting click>=7.0 (from uvicorn>=0.22.0->llama-cpp-python[server]==0.2.38)\r\n",
      "  Obtaining dependency information for click>=7.0 from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\r\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting h11>=0.8 (from uvicorn>=0.22.0->llama-cpp-python[server]==0.2.38)\r\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m58.3/58.3 kB\u001B[0m \u001B[31m3.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.100.0->llama-cpp-python[server]==0.2.38)\r\n",
      "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/28/78/d31230046e58c207284c6b2c4e8d96e6d3cb4e52354721b944d3e1ee4aa5/annotated_types-0.6.0-py3-none-any.whl.metadata\r\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting pydantic-core==2.16.1 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.100.0->llama-cpp-python[server]==0.2.38)\r\n",
      "  Obtaining dependency information for pydantic-core==2.16.1 from https://files.pythonhosted.org/packages/98/19/955b83b6e33b7ac27914860069a918fe49b29c13bc149dc7bb7c60954812/pydantic_core-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\r\n",
      "  Downloading pydantic_core-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\r\n",
      "Collecting idna>=2.8 (from anyio->sse-starlette>=1.6.1->llama-cpp-python[server]==0.2.38)\r\n",
      "  Obtaining dependency information for idna>=2.8 from https://files.pythonhosted.org/packages/c2/e7/a82b05cf63a603df6e68d59ae6a68bf5064484a0718ea5033660af4b54a9/idna-3.6-py3-none-any.whl.metadata\r\n",
      "  Downloading idna-3.6-py3-none-any.whl.metadata (9.9 kB)\r\n",
      "Collecting sniffio>=1.1 (from anyio->sse-starlette>=1.6.1->llama-cpp-python[server]==0.2.38)\r\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\r\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m45.5/45.5 kB\u001B[0m \u001B[31m3.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading fastapi-0.109.1-py3-none-any.whl (92 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m92.1/92.1 kB\u001B[0m \u001B[31m3.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m133.2/133.2 kB\u001B[0m \u001B[31m3.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading numpy-1.26.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m18.3/18.3 MB\u001B[0m \u001B[31m3.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading pydantic_settings-2.1.0-py3-none-any.whl (11 kB)\r\n",
      "Downloading sse_starlette-2.0.0-py3-none-any.whl (9.0 kB)\r\n",
      "Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\r\n",
      "Downloading uvicorn-0.27.0.post1-py3-none-any.whl (60 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m60.7/60.7 kB\u001B[0m \u001B[31m5.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m97.9/97.9 kB\u001B[0m \u001B[31m5.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\r\n",
      "Downloading pydantic-2.6.0-py3-none-any.whl (394 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m394.2/394.2 kB\u001B[0m \u001B[31m2.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading pydantic_core-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.2/2.2 MB\u001B[0m \u001B[31m4.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\r\n",
      "Downloading starlette-0.35.1-py3-none-any.whl (71 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m71.1/71.1 kB\u001B[0m \u001B[31m6.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading anyio-4.2.0-py3-none-any.whl (85 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m85.5/85.5 kB\u001B[0m \u001B[31m5.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\r\n",
      "Downloading idna-3.6-py3-none-any.whl (61 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.6/61.6 kB\u001B[0m \u001B[31m5.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hBuilding wheels for collected packages: llama-cpp-python\r\n",
      "  Running command Building wheel for llama-cpp-python (pyproject.toml)\r\n",
      "  \u001B[92m***\u001B[0m \u001B[1m\u001B[92mscikit-build-core 0.8.0\u001B[0m using \u001B[94mCMake 3.25.1\u001B[0m \u001B[91m(wheel)\u001B[0m\u001B[0m\r\n",
      "  \u001B[92m***\u001B[0m \u001B[1mConfiguring CMake...\u001B[0m\r\n",
      "  2024-02-04 14:31:59,193 - scikit_build_core - WARNING - libdir/ldlibrary: /home/airat/anaconda3/lib/libpython3.11.a is not a real file!\r\n",
      "  2024-02-04 14:31:59,193 - scikit_build_core - WARNING - Can't find a Python library, got libdir=/home/airat/anaconda3/lib, ldlibrary=libpython3.11.a, multiarch=x86_64-linux-gnu, masd=None\r\n",
      "  loading initial cache file /tmp/tmphsfitpci/build/CMakeInit.txt\r\n",
      "  -- The C compiler identification is GNU 12.2.0\r\n",
      "  -- The CXX compiler identification is GNU 12.2.0\r\n",
      "  -- Detecting C compiler ABI info\r\n",
      "  -- Detecting C compiler ABI info - done\r\n",
      "  -- Check for working C compiler: /usr/bin/cc - skipped\r\n",
      "  -- Detecting C compile features\r\n",
      "  -- Detecting C compile features - done\r\n",
      "  -- Detecting CXX compiler ABI info\r\n",
      "  -- Detecting CXX compiler ABI info - done\r\n",
      "  -- Check for working CXX compiler: /usr/bin/c++ - skipped\r\n",
      "  -- Detecting CXX compile features\r\n",
      "  -- Detecting CXX compile features - done\r\n",
      "  -- Found Git: /usr/bin/git (found version \"2.39.2\")\r\n",
      "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\r\n",
      "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\r\n",
      "  -- Found Threads: TRUE\r\n",
      "  -- Warning: ccache not found - consider installing it or use LLAMA_CCACHE=OFF\r\n",
      "  -- CMAKE_SYSTEM_PROCESSOR: x86_64\r\n",
      "  -- x86 detected\r\n",
      "  \u001B[33mCMake Warning (dev) at CMakeLists.txt:21 (install):\r\n",
      "    Target llama has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.\r\n",
      "  This warning is for project developers.  Use -Wno-dev to suppress it.\r\n",
      "  \u001B[0m\r\n",
      "  \u001B[33mCMake Warning (dev) at CMakeLists.txt:30 (install):\r\n",
      "    Target llama has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.\r\n",
      "  This warning is for project developers.  Use -Wno-dev to suppress it.\r\n",
      "  \u001B[0m\r\n",
      "  -- Configuring done\r\n",
      "  -- Generating done\r\n",
      "  -- Build files have been written to: /tmp/tmphsfitpci/build\r\n",
      "  \u001B[92m***\u001B[0m \u001B[1mBuilding project with \u001B[94mNinja\u001B[0m...\u001B[0m\r\n",
      "  [1/22] cd /tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp && /usr/bin/cmake -DMSVC= -DCMAKE_C_COMPILER_VERSION=12.2.0 -DCMAKE_C_COMPILER_ID=GNU -DCMAKE_VS_PLATFORM_NAME= -DCMAKE_C_COMPILER=/usr/bin/cc -P /tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/common/../scripts/gen-build-info-cpp.cmake\r\n",
      "  -- Found Git: /usr/bin/git (found version \"2.39.2\")\r\n",
      "  [2/22] /usr/bin/c++ -D_GNU_SOURCE -D_XOPEN_SOURCE=600  -O3 -DNDEBUG -fPIC -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -std=gnu++11 -MD -MT vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o -c /tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/common/build-info.cpp\r\n",
      "  [3/22] /usr/bin/c++ -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/common/. -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/. -O3 -DNDEBUG -fPIC -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -std=gnu++11 -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o -c /tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/common/console.cpp\r\n",
      "  [4/22] /usr/bin/cc -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/. -O3 -DNDEBUG -fPIC -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wdouble-promotion -march=native -std=gnu11 -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o -c /tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/ggml-alloc.c\r\n",
      "  [5/22] /usr/bin/c++ -DLLAMA_BUILD -DLLAMA_SHARED -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/examples/llava/. -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/examples/llava/../.. -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/examples/llava/../../common -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/. -O3 -DNDEBUG -fPIC -Wno-cast-qual -MD -MT vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o -MF vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o.d -o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o -c /tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/examples/llava/llava.cpp\r\n",
      "  [6/22] /usr/bin/cc -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/. -O3 -DNDEBUG -fPIC -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wdouble-promotion -march=native -std=gnu11 -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o -c /tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/ggml-backend.c\r\n",
      "  [7/22] /usr/bin/c++  -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/common/. -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/. -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/examples/llava/. -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/examples/llava/../.. -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/examples/llava/../../common -O3 -DNDEBUG -MD -MT vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o -MF vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o.d -o vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o -c /tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/examples/llava/llava-cli.cpp\r\n",
      "  [8/22] /usr/bin/c++ -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/common/. -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/. -O3 -DNDEBUG -fPIC -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -std=gnu++11 -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o -c /tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/common/grammar-parser.cpp\r\n",
      "  [9/22] /usr/bin/c++ -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/common/. -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/. -O3 -DNDEBUG -fPIC -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -std=gnu++11 -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o -c /tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/common/sampling.cpp\r\n",
      "  [10/22] /usr/bin/c++ -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/common/. -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/. -O3 -DNDEBUG -fPIC -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -std=gnu++11 -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o -c /tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/common/train.cpp\r\n",
      "  [11/22] /usr/bin/cc -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/. -O3 -DNDEBUG -fPIC -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wdouble-promotion -march=native -std=gnu11 -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o -c /tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/ggml-quants.c\r\n",
      "  [12/22] /usr/bin/c++ -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/common/. -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/. -O3 -DNDEBUG -fPIC -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -std=gnu++11 -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o -c /tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/common/common.cpp\r\n",
      "  [13/22] /usr/bin/cc -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/. -O3 -DNDEBUG -fPIC -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wdouble-promotion -march=native -std=gnu11 -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o -c /tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/ggml.c\r\n",
      "  [14/22] : && /usr/bin/cmake -E rm -f vendor/llama.cpp/libggml_static.a && /usr/bin/ar qc vendor/llama.cpp/libggml_static.a  vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o && /usr/bin/ranlib vendor/llama.cpp/libggml_static.a && :\r\n",
      "  [15/22] : && /usr/bin/cc -fPIC -O3 -DNDEBUG   -shared -Wl,-soname,libggml_shared.so -o vendor/llama.cpp/libggml_shared.so vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o   && :\r\n",
      "  [16/22] /usr/bin/c++ -DLLAMA_BUILD -DLLAMA_SHARED -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/examples/llava/. -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/examples/llava/../.. -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/examples/llava/../../common -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/. -O3 -DNDEBUG -fPIC -Wno-cast-qual -MD -MT vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o -MF vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o.d -o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o -c /tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/examples/llava/clip.cpp\r\n",
      "  [17/22] : && /usr/bin/cmake -E rm -f vendor/llama.cpp/examples/llava/libllava_static.a && /usr/bin/ar qc vendor/llama.cpp/examples/llava/libllava_static.a  vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o && /usr/bin/ranlib vendor/llama.cpp/examples/llava/libllava_static.a && :\r\n",
      "  [18/22] /usr/bin/c++ -DLLAMA_BUILD -DLLAMA_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dllama_EXPORTS -I/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/. -O3 -DNDEBUG -fPIC -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -std=gnu++11 -MD -MT vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o -MF vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o.d -o vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o -c /tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/vendor/llama.cpp/llama.cpp\r\n",
      "  [19/22] : && /usr/bin/c++ -fPIC -O3 -DNDEBUG   -shared -Wl,-soname,libllama.so -o vendor/llama.cpp/libllama.so vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o   && :\r\n",
      "  [20/22] : && /usr/bin/cmake -E rm -f vendor/llama.cpp/common/libcommon.a && /usr/bin/ar qc vendor/llama.cpp/common/libcommon.a  vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o && /usr/bin/ranlib vendor/llama.cpp/common/libcommon.a && :\r\n",
      "  [21/22] : && /usr/bin/c++ -fPIC -O3 -DNDEBUG   -shared -Wl,-soname,libllava.so -o vendor/llama.cpp/examples/llava/libllava.so vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o  -Wl,-rpath,/tmp/tmphsfitpci/build/vendor/llama.cpp:  vendor/llama.cpp/libllama.so && :\r\n",
      "  [22/22] : && /usr/bin/c++ -O3 -DNDEBUG  vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o -o vendor/llama.cpp/examples/llava/llava-cli  -Wl,-rpath,/tmp/tmphsfitpci/build/vendor/llama.cpp:  vendor/llama.cpp/common/libcommon.a  vendor/llama.cpp/libllama.so && :\r\n",
      "  \u001B[92m***\u001B[0m \u001B[1mInstalling project into wheel...\u001B[0m\r\n",
      "  -- Install configuration: \"Release\"\r\n",
      "  -- Installing: /tmp/tmphsfitpci/wheel/platlib/lib/libggml_shared.so\r\n",
      "  -- Installing: /tmp/tmphsfitpci/wheel/platlib/lib/cmake/Llama/LlamaConfig.cmake\r\n",
      "  -- Installing: /tmp/tmphsfitpci/wheel/platlib/lib/cmake/Llama/LlamaConfigVersion.cmake\r\n",
      "  -- Installing: /tmp/tmphsfitpci/wheel/platlib/include/ggml.h\r\n",
      "  -- Installing: /tmp/tmphsfitpci/wheel/platlib/include/ggml-alloc.h\r\n",
      "  -- Installing: /tmp/tmphsfitpci/wheel/platlib/include/ggml-backend.h\r\n",
      "  -- Installing: /tmp/tmphsfitpci/wheel/platlib/lib/libllama.so\r\n",
      "  -- Installing: /tmp/tmphsfitpci/wheel/platlib/include/llama.h\r\n",
      "  -- Installing: /tmp/tmphsfitpci/wheel/platlib/bin/convert.py\r\n",
      "  -- Installing: /tmp/tmphsfitpci/wheel/platlib/bin/convert-lora-to-ggml.py\r\n",
      "  -- Installing: /tmp/tmphsfitpci/wheel/platlib/llama_cpp/libllama.so\r\n",
      "  -- Installing: /tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/llama_cpp/libllama.so\r\n",
      "  -- Installing: /tmp/tmphsfitpci/wheel/platlib/lib/libllava.so\r\n",
      "  -- Set runtime path of \"/tmp/tmphsfitpci/wheel/platlib/lib/libllava.so\" to \"\"\r\n",
      "  -- Installing: /tmp/tmphsfitpci/wheel/platlib/bin/llava-cli\r\n",
      "  -- Set runtime path of \"/tmp/tmphsfitpci/wheel/platlib/bin/llava-cli\" to \"\"\r\n",
      "  -- Installing: /tmp/tmphsfitpci/wheel/platlib/llama_cpp/libllava.so\r\n",
      "  -- Set runtime path of \"/tmp/tmphsfitpci/wheel/platlib/llama_cpp/libllava.so\" to \"\"\r\n",
      "  -- Installing: /tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/llama_cpp/libllava.so\r\n",
      "  -- Set runtime path of \"/tmp/pip-install-b4z5p3xn/llama-cpp-python_6d6bdcd9df4f4a559f5513e3af0af47b/llama_cpp/libllava.so\" to \"\"\r\n",
      "  \u001B[92m***\u001B[0m \u001B[1mMaking wheel...\u001B[0m\r\n",
      "  \u001B[92m***\u001B[0m \u001B[1mCreated\u001B[22m llama_cpp_python-0.2.38-cp311-cp311-manylinux_2_36_x86_64.whl...\u001B[0m\r\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\r\n",
      "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.38-cp311-cp311-manylinux_2_36_x86_64.whl size=2532717 sha256=ebe9c07cd44aa8eb52fd0393694a50c5d8a09ae5436b038043ae4dcd309afa12\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-a6iujf6k/wheels/da/43/07/d4bea667a83a0ec2addb526dfd2ee8fe24df9daee1d7b52560\r\n",
      "Successfully built llama-cpp-python\r\n",
      "Installing collected packages: typing-extensions, sniffio, python-dotenv, numpy, MarkupSafe, idna, h11, diskcache, click, annotated-types, uvicorn, pydantic-core, jinja2, anyio, starlette, pydantic, llama-cpp-python, starlette-context, sse-starlette, pydantic-settings, fastapi\r\n",
      "  Attempting uninstall: typing-extensions\r\n",
      "    Found existing installation: typing_extensions 4.7.1\r\n",
      "    Uninstalling typing_extensions-4.7.1:\r\n",
      "      Removing file or directory /home/airat/anaconda3/lib/python3.11/site-packages/__pycache__/typing_extensions.cpython-311.pyc\r\n",
      "      Removing file or directory /home/airat/anaconda3/lib/python3.11/site-packages/typing_extensions-4.7.1.dist-info/\r\n",
      "      Removing file or directory /home/airat/anaconda3/lib/python3.11/site-packages/typing_extensions.py\r\n",
      "      Successfully uninstalled typing_extensions-4.7.1\r\n",
      "  Attempting uninstall: sniffio\r\n",
      "    Found existing installation: sniffio 1.2.0\r\n",
      "    Uninstalling sniffio-1.2.0:\r\n",
      "      Removing file or directory /home/airat/anaconda3/lib/python3.11/site-packages/sniffio-1.2.0.dist-info/\r\n",
      "      Removing file or directory /home/airat/anaconda3/lib/python3.11/site-packages/sniffio/\r\n",
      "      Successfully uninstalled sniffio-1.2.0\r\n",
      "  Attempting uninstall: python-dotenv\r\n",
      "    Found existing installation: python-dotenv 0.21.0\r\n",
      "    Uninstalling python-dotenv-0.21.0:\r\n",
      "      Removing file or directory /home/airat/anaconda3/bin/dotenv\r\n",
      "      Removing file or directory /home/airat/anaconda3/lib/python3.11/site-packages/dotenv/\r\n",
      "      Removing file or directory /home/airat/anaconda3/lib/python3.11/site-packages/python_dotenv-0.21.0.dist-info/\r\n",
      "      Successfully uninstalled python-dotenv-0.21.0\r\n",
      "  changing mode of /home/airat/anaconda3/bin/dotenv to 755\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.24.3\r\n",
      "    Uninstalling numpy-1.24.3:\r\n",
      "      Removing file or directory /home/airat/anaconda3/bin/f2py\r\n",
      "      Removing file or directory /home/airat/anaconda3/bin/f2py3\r\n",
      "      Removing file or directory /home/airat/anaconda3/bin/f2py3.11\r\n",
      "      Removing file or directory /home/airat/anaconda3/lib/python3.11/site-packages/numpy-1.24.3.dist-info/\r\n",
      "      Removing file or directory /home/airat/anaconda3/lib/python3.11/site-packages/numpy/\r\n",
      "      Successfully uninstalled numpy-1.24.3\r\n",
      "  changing mode of /home/airat/anaconda3/bin/f2py to 755\r\n",
      "  Attempting uninstall: MarkupSafe\r\n",
      "    Found existing installation: MarkupSafe 2.1.1\r\n",
      "    Uninstalling MarkupSafe-2.1.1:\r\n",
      "      Removing file or directory /home/airat/anaconda3/lib/python3.11/site-packages/MarkupSafe-2.1.1.dist-info/\r\n",
      "      Removing file or directory /home/airat/anaconda3/lib/python3.11/site-packages/markupsafe/\r\n",
      "      Successfully uninstalled MarkupSafe-2.1.1\r\n",
      "  Attempting uninstall: idna\r\n",
      "    Found existing installation: idna 3.4\r\n",
      "    Uninstalling idna-3.4:\r\n",
      "      Removing file or directory /home/airat/anaconda3/lib/python3.11/site-packages/idna-3.4.dist-info/\r\n",
      "      Removing file or directory /home/airat/anaconda3/lib/python3.11/site-packages/idna/\r\n",
      "      Successfully uninstalled idna-3.4\r\n",
      "  Attempting uninstall: click\r\n",
      "    Found existing installation: click 8.0.4\r\n",
      "    Uninstalling click-8.0.4:\r\n",
      "      Removing file or directory /home/airat/anaconda3/lib/python3.11/site-packages/click-8.0.4.dist-info/\r\n",
      "      Removing file or directory /home/airat/anaconda3/lib/python3.11/site-packages/click/\r\n",
      "      Successfully uninstalled click-8.0.4\r\n",
      "  changing mode of /home/airat/anaconda3/bin/uvicorn to 755\r\n",
      "  Attempting uninstall: jinja2\r\n",
      "    Found existing installation: Jinja2 3.1.2\r\n",
      "    Uninstalling Jinja2-3.1.2:\r\n",
      "      Removing file or directory /home/airat/anaconda3/lib/python3.11/site-packages/Jinja2-3.1.2.dist-info/\r\n",
      "      Removing file or directory /home/airat/anaconda3/lib/python3.11/site-packages/jinja2/\r\n",
      "      Successfully uninstalled Jinja2-3.1.2\r\n",
      "  Attempting uninstall: anyio\r\n",
      "    Found existing installation: anyio 3.5.0\r\n",
      "    Uninstalling anyio-3.5.0:\r\n",
      "      Removing file or directory /home/airat/anaconda3/lib/python3.11/site-packages/anyio-3.5.0.dist-info/\r\n",
      "      Removing file or directory /home/airat/anaconda3/lib/python3.11/site-packages/anyio/\r\n",
      "      Successfully uninstalled anyio-3.5.0\r\n",
      "  Attempting uninstall: pydantic\r\n",
      "    Found existing installation: pydantic 1.10.8\r\n",
      "    Uninstalling pydantic-1.10.8:\r\n",
      "      Removing file or directory /home/airat/anaconda3/lib/python3.11/site-packages/pydantic-1.10.8.dist-info/\r\n",
      "      Removing file or directory /home/airat/anaconda3/lib/python3.11/site-packages/pydantic/\r\n",
      "      Successfully uninstalled pydantic-1.10.8\r\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\r\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\r\n",
      "spyder 5.4.3 requires pyqt5<5.16, which is not installed.\r\n",
      "spyder 5.4.3 requires pyqtwebengine<5.16, which is not installed.\r\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\r\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\r\n",
      "jupyter-server 1.23.4 requires anyio<4,>=3.1.0, but you have anyio 4.2.0 which is incompatible.\r\n",
      "numba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 1.26.3 which is incompatible.\r\n",
      "anaconda-cloud-auth 0.1.3 requires pydantic<2.0, but you have pydantic 2.6.0 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[0mSuccessfully installed MarkupSafe-2.1.5 annotated-types-0.6.0 anyio-4.2.0 click-8.1.7 diskcache-5.6.3 fastapi-0.109.1 h11-0.14.0 idna-3.6 jinja2-3.1.3 llama-cpp-python-0.2.38 numpy-1.26.3 pydantic-2.6.0 pydantic-core-2.16.1 pydantic-settings-2.1.0 python-dotenv-1.0.1 sniffio-1.3.0 sse-starlette-2.0.0 starlette-0.35.1 starlette-context-0.3.6 typing-extensions-4.9.0 uvicorn-0.27.0.post1\r\n",
      "aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/TheBloke/dolphin-2.6-mistral-7B-dpo-laser-GGUF/resolve/main/dolphin-2.6-mistral-7b-dpo-laser.Q8_0.gguf -d /content/models/ -o dolphin-2.6-mistral-7b-dpo-laser.Q8_0.gguf\n",
      "\u001B[35m[\u001B[0m#40c263 0B/0B CN:1 DL:\u001B[32m0B\u001B[0m\u001B[35m]\u001B[0m\u001B[0m                      \r\n",
      "02/04 14:32:29 [\u001B[1;31mERROR\u001B[0m] CUID#7 - Download aborted. URI=https://huggingface.co/TheBloke/dolphin-2.6-mistral-7B-dpo-laser-GGUF/resolve/main/dolphin-2.6-mistral-7b-dpo-laser.Q8_0.gguf\r\n",
      "Exception: [AbstractCommand.cc:403] errorCode=18 URI=https://cdn-lfs-us-1.huggingface.co/repos/4c/89/4c892259969b7d80565e4411bb13cceeb5c268b260f3c85b0a688ec67aa9e4d4/1831ea2eb9ed09cd10d37f99703c597f77d59b7b7e3f05875ce5df919bfc458b?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27dolphin-2.6-mistral-7b-dpo-laser.Q8_0.gguf%3B+filename%3D%22dolphin-2.6-mistral-7b-dpo-laser.Q8_0.gguf%22%3B&Expires=1707291449&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwNzI5MTQ0OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzRjLzg5LzRjODkyMjU5OTY5YjdkODA1NjVlNDQxMWJiMTNjY2VlYjVjMjY4YjI2MGYzYzg1YjBhNjg4ZWM2N2FhOWU0ZDQvMTgzMWVhMmViOWVkMDljZDEwZDM3Zjk5NzAzYzU5N2Y3N2Q1OWI3YjdlM2YwNTg3NWNlNWRmOTE5YmZjNDU4Yj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=d1dkddxSQXAWF05gf66k7wW9IQeCRPNWe7DLZSCPEeDJCpKdY5NAVIZR6EPDtB-iIcBknnpVfda-iGoPJpzsyA11vOp-sDzdWUYeb6Dl3oAhbFpb0nuO75Wyrq0qu9FbhmtWvG2toScDkRv7KWx256zHaG76Nt9Qj-vzFxV%7E8%7EA61z%7Eg%7EHH2WpCGEPzJk7XAUq8yMk35zI2oE%7EeSZ5m00vIBSy0TsUZkZJF1YVIofNttuVci4maxefJ1qQsS1Ryh3EeY2fm5Ii5AHhAr1cYqeV2bFX7oJzLz%7EWixOml%7Ea4kZuc2f%7E4bSG4NT0iNspDTVJ69w8JA%7ETtAEN8MU1JIktw__&Key-Pair-Id=KCD77M1F0VK2B\r\n",
      "  -> [RequestGroup.cc:761] errorCode=18 Download aborted.\r\n",
      "  -> [util.cc:1948] errNum=13 errorCode=18 Failed to make the directory /content/models/, cause: Permission denied\r\n",
      "\r\n",
      "Download Results:\r\n",
      "gid   |stat|avg speed  |path/URI\r\n",
      "======+====+===========+=======================================================\r\n",
      "40c263|\u001B[1;31mERR\u001B[0m |       0B/s|/content/models//dolphin-2.6-mistral-7b-dpo-laser.Q8_0.gguf\r\n",
      "\r\n",
      "Status Legend:\r\n",
      "(ERR):error occurred.\r\n",
      "\r\n",
      "aria2 will resume download if the transfer is restarted.\r\n",
      "If there are any errors, then see the log file. See '-l' option in help/man page for details.\r\n",
      "python -m llama_cpp.server --host 127.0.0.1 --port 1234 --model /content/models/dolphin-2.6-mistral-7b-dpo-laser.Q8_0.gguf --model_alias dolphin-2.6-mistral-7b-dpo-laser --chat_format chatml --n_gpu_layers 33 --offload_kqv True --n_threads 12 --n_batch 512 --n_ctx 8192 --cache False & lt --port 1234 --subdomain ai-tutor-server-api\n",
      "/bin/bash: line 1: lt: command not found\r\n"
     ]
    }
   ],
   "source": [
    "#@title Start the llama-cpp-server\n",
    "\n",
    "#@markdown If unsure about the branch, write \"main\" or leave it blank.\n",
    "%cd /content\n",
    "!apt-get -y install -qq aria2\n",
    "!npm install -g localtunnel\n",
    "!export CUDACXX=/usr/local/cuda/bin/nvcc\n",
    "!export CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\"\n",
    "!export FORCE_CMAKE=1\n",
    "!pip install llama-cpp-python[server]==0.2.38 --force-reinstall --upgrade --no-cache-dir --verbose\n",
    "\n",
    "# Parameters\n",
    "model_url = \"TheBloke/dolphin-2.6-mistral-7B-dpo-laser-GGUF\" #@param {type:\"string\"}\n",
    "model_alias = \"dolphin-2.6-mistral-7b-dpo-laser\" #@param {type:\"string\"}\n",
    "chat_format = \"chatml\" #@param {type:\"string\"}\n",
    "n_gpu_layers = 33 #@param {type:\"integer\"}\n",
    "offload_kqv = True #@param {type:\"boolean\"}\n",
    "n_threads = 12 #@param {type:\"integer\"}\n",
    "n_batch = 512 #@param {type:\"integer\"}\n",
    "n_ctx = 8192 #@param {type:\"integer\"}\n",
    "cache = False #@param {type:\"boolean\"}\n",
    "\n",
    "model_url = model_url.strip()\n",
    "model = \"\"\n",
    "if model_url != \"\":\n",
    "    if not model_url.startswith('http'):\n",
    "        model_url = f\"https://huggingface.co/{model_url}/resolve/main/{model_alias}.Q8_0.gguf\"        \n",
    "\n",
    "# Download the model\n",
    "models_dir = f\"/content/models/\"\n",
    "download_cmd = f\"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {model_url} -d {models_dir} -o {model_alias}.Q8_0.gguf\"\n",
    "print(download_cmd)\n",
    "!$download_cmd\n",
    "\n",
    "# Start the server\n",
    "model = f\"{models_dir}{model_alias}.Q8_0.gguf\"\n",
    "port = 1234\n",
    "\n",
    "cmd = f\"python -m llama_cpp.server --host 127.0.0.1 --port {port} --model {model} --model_alias {model_alias} --chat_format {chat_format} --n_gpu_layers {n_gpu_layers} --offload_kqv {offload_kqv} --n_threads {n_threads} --n_batch {n_batch} --n_ctx {n_ctx} --cache {cache} & lt --port {port} --subdomain ai-tutor-server-api\"\n",
    "print(cmd)\n",
    "!$cmd"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyMd/BbIoY7Mr2J+rD54WhFv",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
